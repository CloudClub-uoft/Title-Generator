{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset: torchvision.datasets, batch_size=32, splits=[0.8,0.1,0.1]) -> torch.utils.data.DataLoader:\n",
    "    '''\n",
    "    dataset: torchvision.datasets a transformer dataset for training, testing, and validation\n",
    "    batch_size: int\n",
    "    splits: list(str) train-validation-test split\n",
    "    return: DataLoader\n",
    "    '''\n",
    "\n",
    "    assert sum(splits) == 1, \"ensure sum of train-validation-test split adds up to 1\"\n",
    "\n",
    "    # perform split\n",
    "    size = len(dataset)\n",
    "    l1, l2 = int(size*splits[0]), int(size*splits[1])\n",
    "    l3 = size - l1 - l2\n",
    "\n",
    "    train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "        dataset,\n",
    "        [l1, l2, l3],\n",
    "        generator=torch.Generator().manual_seed(999)\n",
    "    )\n",
    "\n",
    "    # get data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, model, loss_function, optimizer, scheduler=None, epochs=30): \n",
    "    losses_over_epochs = []\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    for epoch in epochs:\n",
    "        start = time.time()\n",
    "        total_loss = 0\n",
    "        for (source, target, labels, source_mask, target_mask) in data_loader:\n",
    "            # forward step\n",
    "            out = model(source, target, source_mask, target_mask)\n",
    "\n",
    "            # loss\n",
    "            loss = loss_function(out, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # back propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # learning rate scheduler update\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # finished one epoch of training\n",
    "        end = time.time()\n",
    "        print(f\"Completed epoch {epoch+1} | average loss: {total_loss/num_batches} | time: {end-start}s\")\n",
    "        losses_over_epochs.append(total_loss/num_batches)\n",
    "\n",
    "    return losses_over_epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a2bd2daeb0c020ce43de5ad165562b29120817cbbcc4b7133ff9fcae7210d52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
