{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, embed_dim, input_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_heads = embed_dim // num_heads     # dim_heads aka d_k\n",
    "\n",
    "        self.q_lin = nn.Linear(input_dim, embed_dim)\n",
    "        self.k_lin = nn.Linear(input_dim, embed_dim)\n",
    "        self.v_lin = nn.Linear(input_dim, embed_dim)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.size(0)\n",
    "        num_heads, dim_heads = self.num_heads, self.dim_heads\n",
    "\n",
    "        q = self.q_lin(q).reshape(batch_size, -1, num_heads, dim_heads).transpose(1, 2)\n",
    "        k = self.k_lin(k).reshape(batch_size, -1, num_heads, dim_heads).transpose(1, 2)\n",
    "        v = self.v_lin(v).reshape(batch_size, -1, num_heads, dim_heads).transpose(1, 2)\n",
    "\n",
    "        scores = attention(q, k, v, dim_heads, mask=mask, dropout=self.dropout)\n",
    "        \n",
    "        scores = scores.transpose(1, 2).contiguous().reshape(batch_size, -1, self.embed_dim)\n",
    "\n",
    "        output = self.out_proj(scores)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is qingyuan's function\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    scaled_dot = torch.matmul(q, k.transpose(-2, -1)) / sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled_dot = scaled_dot.masked_fill(mask == 0, -1e9)\n",
    "    scaled_dot = F.softmax(scaled_dot, dim=-1)\n",
    "    if dropout is not None:\n",
    "        scaled_dot = dropout(scaled_dot)\n",
    "    output =  torch.matmul(scaled_dot, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7.1008e-01,  4.1344e+00,  4.2444e+00, -2.2098e-01,  2.4778e+00,\n",
      "           1.8659e+00, -3.6529e-01, -1.8282e-01, -2.3154e+00,  2.8329e+00,\n",
      "           5.9769e+00, -2.4970e+00,  9.0717e-01, -1.3421e+00, -1.3616e+00,\n",
      "          -1.5755e+00,  5.6827e+00,  9.1596e-01, -1.2586e+00,  5.6572e-01,\n",
      "           8.2308e-01,  2.1544e+00,  3.3808e+00, -1.1160e+00,  1.8727e+00,\n",
      "           1.1822e+00,  2.2700e+00,  9.9076e-01,  1.6973e+00,  6.4900e-01,\n",
      "          -7.5532e-01,  1.9348e+00, -1.7630e+00, -3.0904e+00, -1.4175e+00,\n",
      "           6.9837e-01,  2.9211e+00,  2.9955e+00, -1.1018e+00, -9.8237e-01,\n",
      "          -1.2206e+00,  8.6352e-01, -1.9078e+00,  7.8156e-01, -1.8281e+00,\n",
      "          -7.4415e-01, -2.3792e+00, -2.6369e+00,  1.2690e+00,  1.0197e+00,\n",
      "           3.6274e-01,  1.6704e+00, -3.4851e+00, -1.5627e-01,  2.7131e+00,\n",
      "           7.3606e-01,  2.3178e+00,  2.8196e+00, -1.5758e+00,  2.8286e+00,\n",
      "           1.0097e+00, -2.9510e-01,  7.4239e-01,  2.6189e-01, -4.6646e+00,\n",
      "          -3.9559e-01, -8.6237e-01, -1.8434e+00,  6.7236e+00, -3.5793e+00,\n",
      "           7.9112e-01, -2.0660e+00, -7.5204e-01, -1.1555e+00,  3.2957e-01,\n",
      "          -4.0535e-01, -1.8621e+00,  3.5163e+00,  2.1164e+00,  2.1927e+00,\n",
      "           7.9280e-01,  6.2599e-02,  5.2885e+00,  5.3304e-01,  2.0268e+00,\n",
      "          -3.4811e-01,  6.1007e+00,  1.4368e+00, -1.9946e+00, -2.2434e+00,\n",
      "           1.0713e+00, -5.1233e+00,  7.3475e-01, -1.6444e+00, -1.6539e+00,\n",
      "          -5.1390e-01,  2.4555e+00,  8.7619e-01,  7.9879e-01,  4.5995e+00,\n",
      "          -1.7478e+00, -3.1593e+00, -1.2562e+00, -3.6168e-02,  1.6545e+00,\n",
      "          -1.3597e+00, -7.4577e-01, -2.0222e+00,  1.5855e+00, -4.6963e+00,\n",
      "           2.2951e+00, -1.3020e+00,  2.1388e+00,  4.8075e-01, -1.9708e+00,\n",
      "           1.7692e+00,  2.6307e+00, -1.7338e+00,  3.5488e+00, -1.8423e+00,\n",
      "           6.3430e-01,  1.1402e+00,  2.3180e+00, -3.1437e+00,  2.0571e+00,\n",
      "          -4.8320e-01,  5.8751e+00,  1.9566e+00, -1.7425e-01,  2.7808e+00,\n",
      "           9.3880e-01, -2.3935e+00,  5.4270e+00, -1.8200e+00,  1.8634e+00,\n",
      "          -2.9921e+00, -7.6943e-01, -9.4354e-01, -2.2263e+00,  4.5234e+00,\n",
      "           1.2611e+00, -3.3551e+00,  1.7775e+00, -9.0857e-01, -2.2204e+00,\n",
      "          -2.5892e+00,  1.3584e+00,  3.4744e+00,  1.5526e+00,  8.0963e-01,\n",
      "          -8.2640e-01, -1.9879e+00,  1.2834e+00,  3.1189e-02,  1.0808e+00,\n",
      "          -4.6554e+00,  4.0210e+00,  2.8121e+00,  3.3682e+00,  1.9260e+00,\n",
      "           3.0808e+00,  2.2966e+00,  1.0057e+00, -9.1865e-01,  3.1788e+00,\n",
      "          -2.7245e+00,  2.9673e+00, -1.0317e+00,  1.6707e+00, -3.2493e+00,\n",
      "           5.9881e-01, -1.8204e+00, -9.9808e-01, -2.5478e-01,  8.2977e-01,\n",
      "           1.6711e+00, -2.3457e+00,  1.3203e+00,  5.3432e-01, -5.3757e-03,\n",
      "           3.5123e+00,  1.2243e+00,  2.2927e-01, -1.7834e-01,  2.9593e-02,\n",
      "          -3.3684e-01, -1.9690e+00, -3.0528e+00,  5.0302e+00, -1.4997e+00,\n",
      "          -2.6177e+00, -1.8307e+00, -2.1679e-02,  5.5168e+00, -2.1547e+00,\n",
      "          -7.9557e-01,  1.4034e+00, -1.0126e+00,  4.0041e+00, -1.2600e+00,\n",
      "          -1.8569e+00, -1.1151e+00, -2.6834e+00,  1.8704e+00, -2.4174e+00,\n",
      "           3.3088e-01, -2.9359e+00, -6.0468e-01, -1.2435e+00, -2.2087e+00,\n",
      "           1.5272e+00, -1.3473e+00, -2.6519e+00, -4.1643e-01, -2.7016e-01,\n",
      "          -4.2571e+00, -3.1670e-01, -1.4628e+00,  1.3024e+00,  1.8442e+00,\n",
      "           2.0887e+00,  1.4975e+00, -2.2740e+00, -3.1869e+00, -2.1100e+00,\n",
      "          -9.8667e-01,  3.2475e-01, -9.8328e-01,  5.4069e+00, -7.0752e-01,\n",
      "           6.4480e-01, -1.1584e+00,  6.0536e+00, -1.0328e+00,  2.4034e+00,\n",
      "           2.9753e+00, -1.4520e+00, -3.6180e+00, -1.3814e+00, -5.9078e-01,\n",
      "           5.7987e-01, -1.7921e+00,  2.8748e+00,  2.2667e+00,  2.8830e+00,\n",
      "           1.7589e+00,  3.5083e-01,  1.1446e+00,  3.0210e+00, -1.4500e+00,\n",
      "          -8.3171e-01, -1.6613e+00, -2.3805e-01,  5.2728e-01, -1.6842e+00,\n",
      "           9.1978e-01, -1.7252e+00, -1.6904e+00,  2.8809e+00, -1.2153e+00,\n",
      "           1.6086e+00, -3.1070e-02,  2.6761e-01,  6.7774e-03,  4.3281e+00,\n",
      "           6.8465e-01, -1.8362e-01, -3.1427e-01,  1.8499e+00,  8.9529e-01,\n",
      "          -1.8175e+00,  6.0657e-01, -2.9083e+00,  1.0447e+00,  8.6924e-01,\n",
      "          -2.5854e-01, -2.4566e+00, -2.6827e+00, -4.4731e-01,  1.9151e+00,\n",
      "           4.2783e+00,  1.3639e+00,  1.1597e+00, -1.0829e+00, -3.5085e-01,\n",
      "           3.9005e+00,  1.4720e+00,  2.0001e+00,  2.3376e+00,  2.1327e+00,\n",
      "          -2.0690e+00,  4.4711e-01, -7.6098e-01,  2.9717e+00, -2.6991e-01,\n",
      "           5.1777e-01, -4.8445e+00, -2.0722e+00, -1.4999e+00, -2.5574e-01,\n",
      "          -1.6376e+00, -1.0613e+00,  1.0186e+00, -6.1570e-01,  2.8379e+00,\n",
      "           2.2202e+00,  4.2458e-01, -2.9319e+00,  3.1673e-01, -2.0447e+00,\n",
      "           2.9174e+00,  1.2385e+00,  2.3451e+00,  1.2161e+00,  1.4060e+00,\n",
      "          -9.0148e-01,  8.0368e-01, -9.5250e-01,  2.4314e+00,  5.8591e-01,\n",
      "          -1.4011e-01,  2.1398e+00, -6.3991e-01,  4.6127e-01,  2.9969e+00,\n",
      "           1.0611e+00,  3.5924e-01,  2.3258e+00,  1.8379e+00,  2.7439e+00,\n",
      "           1.3547e+00,  1.6507e+00,  1.5386e+00, -4.3434e-01, -1.6681e+00,\n",
      "           3.6104e+00,  2.1749e+00, -4.4842e+00,  2.1475e+00,  2.7790e+00,\n",
      "          -1.3175e+00,  1.3143e-01, -1.3973e+00, -1.8100e+00, -3.0494e+00,\n",
      "           1.9835e-01, -4.6107e-01,  4.5448e+00, -2.1411e+00, -1.2969e+00,\n",
      "           1.9386e+00,  2.9191e+00,  2.3373e-01, -2.8941e+00,  1.6295e+00,\n",
      "           1.5001e+00, -1.7877e+00, -1.8238e+00,  1.4475e+00,  5.3344e-01,\n",
      "           1.0546e+00, -8.5370e-01,  1.0551e+00,  4.3041e-02, -1.3190e+00,\n",
      "          -3.4910e+00, -5.7615e-01, -1.2599e+00,  1.7996e+00, -2.8401e+00,\n",
      "           3.7696e+00, -1.5390e-01, -6.1693e+00, -1.0473e+00, -1.8282e+00,\n",
      "          -1.4439e+00,  5.8901e+00,  2.1652e+00,  2.7386e-01, -6.1030e-01,\n",
      "          -2.2794e-01, -1.4802e-01, -1.1257e+00,  2.0790e+00, -2.7465e+00,\n",
      "           3.0729e+00, -8.0723e-01,  1.7402e+00, -1.4092e+00, -1.2322e+00,\n",
      "          -2.3990e+00, -8.0675e-01, -1.2777e+00, -1.0210e+00,  2.2855e+00,\n",
      "          -1.0357e-01,  1.0664e-01,  7.5369e-01, -8.8149e-01,  1.4405e+00,\n",
      "           2.0246e+00,  4.4574e+00,  1.5403e+00,  3.1646e+00, -2.4668e+00,\n",
      "          -2.6897e-01, -8.6360e-02,  8.5367e-01, -1.8011e+00, -4.4701e+00,\n",
      "          -1.1571e+00,  6.7674e-01,  1.2432e+00, -1.0937e-01,  1.0438e+00,\n",
      "           1.0304e+00, -2.0606e-01,  4.2202e+00, -2.6634e+00,  7.0213e-01,\n",
      "          -3.8188e-01,  1.7958e-01,  2.4329e+00,  1.1129e+00, -6.6712e-01,\n",
      "          -5.0420e+00, -3.5265e+00,  2.8725e-01, -5.6082e+00,  4.8130e+00,\n",
      "           1.6244e+00,  1.8891e+00,  1.0508e-01, -8.9657e-01, -1.4460e-01,\n",
      "          -2.5511e+00,  1.5148e+00,  6.8528e-01, -4.8442e-01, -1.3593e+00,\n",
      "           3.1332e+00, -5.5162e-01,  1.0827e+00, -1.1647e+00,  1.5867e+00,\n",
      "          -2.6836e+00, -5.7423e-01, -3.0920e+00, -2.4953e+00,  1.0331e+00,\n",
      "           3.7838e+00, -1.2167e+00,  3.5897e+00, -9.4085e-01,  6.3135e-01,\n",
      "          -5.4409e-01,  7.1700e+00, -6.0536e-01,  7.5283e-01,  3.9182e-01,\n",
      "           1.8983e-01, -1.8517e+00,  1.8631e+00, -1.7993e+00, -4.1295e-01,\n",
      "          -1.1630e+00,  2.2203e+00, -1.8630e+00, -7.6362e-01,  9.8480e-01,\n",
      "          -4.7066e+00,  8.1631e-01, -1.3310e+00,  1.0060e+00,  1.4915e-01,\n",
      "          -1.0721e+00, -9.5345e-01,  2.1212e+00, -6.1224e-01, -4.0281e-01,\n",
      "          -1.6221e+00, -1.6277e+00,  1.3962e+00, -5.8200e-02,  2.0631e+00,\n",
      "          -2.5103e+00,  2.7020e+00,  1.1999e+00, -1.2828e+00,  1.9941e+00,\n",
      "           2.2534e-01,  3.2492e+00,  2.3698e+00, -3.9689e-01,  9.6661e-01,\n",
      "           2.3952e+00, -6.9945e-01, -6.0496e-01,  1.9051e-01,  3.0779e+00,\n",
      "           1.6458e+00,  1.2674e+00,  6.8204e-01, -1.4807e+00, -3.0081e+00,\n",
      "           1.3821e+00,  5.5007e-01, -9.8758e-02,  4.6560e+00, -4.5771e+00,\n",
      "          -5.1509e-01, -2.2759e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 512\n",
    "num_heads = 8\n",
    "\n",
    "q = torch.tensor([[0, 10, 0]], dtype=torch.float32)\n",
    "k = torch.tensor([[0, 10, 0]], dtype=torch.float32)\n",
    "v = torch.tensor([[0, 10, 0]], dtype=torch.float32)\n",
    "input_dim = 3\n",
    "\n",
    "mh = MultiHeadAttention(num_heads, embed_dim, input_dim)\n",
    "scores = mh.forward(q, k, v)\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e28aa8f00749c703ae5b639866da39d3cef40d6068bc8b931f821ff6e0150f69"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cloudai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
